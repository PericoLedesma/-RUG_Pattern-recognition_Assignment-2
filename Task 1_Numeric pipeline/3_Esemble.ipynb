{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84ea3cac",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6baade51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "### From sklearn - Preprocesing \n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Dimension reduction \n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Clustering \n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# K-fold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "\n",
    "# From sklearn - Model creation\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "from sklearn import metrics \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a8d2ae",
   "metadata": {},
   "source": [
    "-----\n",
    "# Reading files and merging features with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0bac7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = pd.read_csv(\"Genes\\data.csv\")\n",
    "dataset = pd.read_csv('/Users/pedrorodriguezdeledesmajimenez/1_Coding/Datasets/RUG_Pattern-recognition_Assignment-2/Task 1/Genres/data.csv')\n",
    "\n",
    "#labels = pd.read_csv(\"Genes\\labels.csv\")\n",
    "dataset_labels =pd.read_csv('/Users/pedrorodriguezdeledesmajimenez/1_Coding/Datasets/RUG_Pattern-recognition_Assignment-2/Task 1/Genres/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c238d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging both datasets and removing first column\n",
    "dataset = pd.merge(dataset, dataset_labels, on='Unnamed: 0').drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c7f917",
   "metadata": {},
   "source": [
    "----\n",
    "# Analizing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177a57ba",
   "metadata": {},
   "source": [
    "###  Encode the labels of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08ac19fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the labels and updaate values\n",
    "le = preprocessing.LabelEncoder()\n",
    "dataset[\"Class\"] = le.fit_transform(dataset_labels.drop(\"Unnamed: 0\", axis=1).values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa5f0414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let´s store all the labels\n",
    "keys = le.classes_\n",
    "\n",
    "# And now store labels with their encoded value \n",
    "values = le.transform(le.classes_)\n",
    "dictionary = dict(zip(keys, values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f6f281",
   "metadata": {},
   "source": [
    "### Normalize the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b38a0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets store the dataset values without the columns titles\n",
    "x = dataset.iloc[:, :-1].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02904444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let´s create an instance with the normalice function\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "# Let´s fit the normilice function\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "# Let´s put in the dataframe the values scaled\n",
    "dataset.iloc[:, :-1] = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c9e76f",
   "metadata": {},
   "source": [
    "### Output of preprocesing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d47848a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(801, 20532)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e2761e",
   "metadata": {},
   "source": [
    "--------------\n",
    "# Model Implementation:  Esemble methods "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876478f3",
   "metadata": {},
   "source": [
    "###  80% Training data, 20% test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f13ed16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected value dimension reduction \n",
    "lda = LinearDiscriminantAnalysis(n_components=4)\n",
    "\n",
    "# Apply PCA in input vector\n",
    "lda.fit(dataset.iloc[:,:-1],dataset.iloc[:,-1]) \n",
    "\n",
    "# Save results in an np.array\n",
    "reduced = lda.transform(dataset.iloc[:,:-1].values)\n",
    "\n",
    "# Save labels in an np.array\n",
    "x = dataset['Class'].to_numpy()\n",
    "\n",
    "# Create final dataframe with reduced dimensions\n",
    "dataset_reduced_LDA = pd.DataFrame(np.column_stack((reduced, x)))\n",
    "\n",
    "#For origianl data as input\n",
    "input_data = dataset.iloc[:,:-1].values\n",
    "label_data = dataset.iloc[:,-1].values\n",
    "\n",
    "#For PCA REDUCED data as input\n",
    "#input_data = dataset_reduced_LDA.iloc[:,:-1].values\n",
    "#label_data = dataset_reduced_LDA.iloc[:,-1].values\n",
    "\n",
    "# We split the data  \n",
    "X_train, X_test, y_train, y_test = train_test_split(input_data,label_data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6675e838",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Pipeline 1: inside we are giving a list of tuples \n",
    "pipeline_lr = Pipeline([('lr_classifier', LogisticRegression())])\n",
    "\n",
    "# Pipeline 2\n",
    "pipeline_dt = Pipeline([('dt_classifier', DecisionTreeClassifier())])\n",
    "\n",
    "# Pipeline 3\n",
    "pipeline_randomforest = Pipeline([('rf_classifier', RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed656e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets make a list of pipelines\n",
    "pipelines = [pipeline_lr, pipeline_dt, pipeline_randomforest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d5de1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable declaration\n",
    "\n",
    "best_accuracy = 0.0\n",
    "best_classifier = 0 \n",
    "best_pipeline = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0009bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of pipelines and classifier types for ease of reference\n",
    "\n",
    "pipe_dict = {0: 'Logistic Regression', 1: 'Decision Tree', 2: 'RandomForest'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ccfcd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pedrorodriguezdeledesmajimenez/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Fit the pipelines\n",
    "for pipe in pipelines:\n",
    "    pipe.fit(X_train, y_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d5a6a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test accuracy: 0.9937888198757764\n",
      "Decision Tree Test accuracy: 0.9937888198757764\n",
      "RandomForest Test accuracy: 0.9875776397515528\n"
     ]
    }
   ],
   "source": [
    "# Display\n",
    "\n",
    "for i, model in enumerate(pipelines):\n",
    "    print(\"{} Test accuracy: {}\".format(pipe_dict[i], model.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2714d0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier with the best accuracy: Logistic Regression\n"
     ]
    }
   ],
   "source": [
    "for i, model in enumerate(pipelines):\n",
    "    if model.score(X_test, y_test) > best_accuracy:\n",
    "        best_accuracy = model.score(X_test, y_test)\n",
    "        best_pipeline = model\n",
    "        best_classifier = i\n",
    "        \n",
    "print('Classifier with the best accuracy: {}' .format(pipe_dict[best_classifier]))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3be8c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "dt = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "labels = ['Logistic Regression', 'Decision Tree', 'Random Forest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c560f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pedrorodriguezdeledesmajimenez/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('Logistic Regression', LogisticRegression()),\n",
       "                             ('Decision Tree', DecisionTreeClassifier()),\n",
       "                             ('Random Forest', RandomForestClassifier())])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "evc = VotingClassifier(estimators = [(labels[0],lr),(labels[1], dt), (labels[2], rf)], voting = 'hard')\n",
    "\n",
    "evc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98b8c95d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9875776397515528"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7a4dfc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pedrorodriguezdeledesmajimenez/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/pedrorodriguezdeledesmajimenez/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/pedrorodriguezdeledesmajimenez/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/pedrorodriguezdeledesmajimenez/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/pedrorodriguezdeledesmajimenez/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9962577639751553"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(evc,input_data,label_data, cv=5).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
