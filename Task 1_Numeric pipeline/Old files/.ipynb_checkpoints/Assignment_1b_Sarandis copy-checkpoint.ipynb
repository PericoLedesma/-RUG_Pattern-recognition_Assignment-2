{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84ea3cac",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6baade51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a7b210",
   "metadata": {},
   "source": [
    "# Data Description and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bac7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading files and merging features with labels\n",
    "#dataset = pd.read_csv(\"Genes\\data.csv\")\n",
    "#dataset_labels = pd.read_csv(\"Genes\\labels.csv\")\n",
    "\n",
    "#dataset = pd.read_csv(\"Genes\\data.csv\")\n",
    "dataset = pd.read_csv('/Users/pedrorodriguezdeledesmajimenez/1_Coding/Datasets/RUG_Pattern-recognition_Assignment-2/Task 1/Genres/data.csv')\n",
    "\n",
    "#labels = pd.read_csv(\"Genes\\labels.csv\")\n",
    "dataset_labels =pd.read_csv('/Users/pedrorodriguezdeledesmajimenez/1_Coding/Datasets/RUG_Pattern-recognition_Assignment-2/Task 1/Genres/labels.csv')\n",
    "\n",
    "\n",
    "dataset = pd.merge(dataset, labels, on='Unnamed: 0').drop(\"Unnamed: 0\", axis=1)\n",
    "\n",
    "\n",
    "# Normalize tha features except tha labels\n",
    "x = dataset.iloc[:, :-1].values\n",
    "standard_scaler = preprocessing.StandardScaler()\n",
    "x_scaled = standard_scaler.fit_transform(x)\n",
    "dataset.iloc[:, :-1] = pd.DataFrame(x_scaled)\n",
    "\n",
    "print(f'Dataset consists of {dataset.shape[0]} input sample vectors, each vector has {dataset.shape[1]} '\\\n",
    "      f'gene features.\\nAlso the availbale classes are {len(dataset[\"Class\"].unique())}.'\\\n",
    "      f' The possible choises are {\", \".join(val for val in dataset.Class.unique())}.')\n",
    "class_counts = dataset.Class.value_counts()\n",
    "print(f'As we can see, we have class imbalance.\\n\\n{class_counts.to_string()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0f03f8",
   "metadata": {},
   "source": [
    "### a) Apply PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbe7359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PCA object to keep 95% of variance\n",
    "pca = PCA(0.95)\n",
    "\n",
    "# Apply PCA in input vector\n",
    "pca.fit(dataset.iloc[:,:-1])\n",
    "\n",
    "# Save results in an np.array\n",
    "reduced = pca.transform(dataset.iloc[:,:-1])\n",
    "\n",
    "#Save labels in an np.array\n",
    "x = dataset['Class'].to_numpy()\n",
    "\n",
    "# Create final dataframe with reduced dimensions\n",
    "decomposed = pd.DataFrame(np.column_stack((reduced, x)))\n",
    "\n",
    "#Rename columns\n",
    "for column in decomposed.columns:\n",
    "    if column<len(decomposed.columns)-1:\n",
    "        decomposed.rename(columns={column : f\"PCA{column+1}\"}, inplace=True)\n",
    "    else:\n",
    "        decomposed.rename(columns={column : \"Label\"}, inplace=True)\n",
    "        \n",
    "print(f'Data size after PCA is: {decomposed.shape}.')\n",
    "\n",
    "print(f'Still, there are many features, but with no significance at all. We intend to keep a minimal number of\\n' \\\n",
    "      f'features while keeping the variance/information as high as possible\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc06c897",
   "metadata": {},
   "source": [
    "## b) Further reduction of dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f7e14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating variance ration of each component and cummulative sum.  \n",
    "\n",
    "exp_var_pca = pca.explained_variance_ratio_\n",
    "\n",
    "cum_sum_eigenvalues = np.cumsum(exp_var_pca)\n",
    "\n",
    "# Plot with regards of components\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(0,len(exp_var_pca[:150])), exp_var_pca[:150], alpha=0.5, \n",
    "        align='center', label='Individual explained variance')\n",
    "plt.step(range(0,len(cum_sum_eigenvalues[:150])), cum_sum_eigenvalues[0:150], \n",
    "         where='mid',label='Cumulative explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal component index')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Explained_variance_VS_Cumulative_sum.png\")\n",
    "plt.show()\n",
    "\n",
    "print(f'We decided to keep 100 components. This translates to about 71% information kept.')\n",
    "\n",
    "#Pick only the first 100 componets which combine for 71% of information\n",
    "\n",
    "decomposed = pd.concat([decomposed.iloc[:,:100],decomposed.iloc[:,-1]], axis=1)\n",
    "\n",
    "print(f'\\nAfter further elimination of features we end up with the final form of the data.\\n\\n{decomposed.head()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28860663",
   "metadata": {},
   "source": [
    "### c) Finding outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb434c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search for outliers in dataset\n",
    "lof = LocalOutlierFactor()\n",
    "# fit_predict return a numpy array of 1 if not an outlier and -1 if an outlier\n",
    "outliers = lof.fit_predict(decomposed.iloc[:,:-1])\n",
    "\n",
    "# select all rows that are not outliers\n",
    "mask = outliers != -1\n",
    "\n",
    "#unpack the mask to keep only non-outlier examples\n",
    "decomposed = decomposed[[*mask]]\n",
    "\n",
    "print(f'Data size after removing outliers is: {decomposed.shape}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b438a11",
   "metadata": {},
   "source": [
    "### d) T-sne for visualization of the remainig dataset in two dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9e85b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = TSNE(n_components = 2, learning_rate=20)\n",
    "tsne_features = m.fit_transform(decomposed.drop('Label', axis=1))\n",
    "\n",
    "decomposed.loc[:,'x'] = tsne_features[:,0]\n",
    "decomposed.loc[:,'y'] = tsne_features[:,1]\n",
    "sns.scatterplot(x=\"x\", y=\"y\", hue='Label', data=decomposed)\n",
    "plt.savefig(\"TSNE_visualization_algorithm.png\")\n",
    "plt.show()\n",
    "decomposed.drop(['x', 'y'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b057249",
   "metadata": {},
   "source": [
    "# Model Implementation: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70db7489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the labels and updaate values\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "decomposed[\"Label\"] = le.fit_transform(decomposed.iloc[:,-1].values.ravel())\n",
    "keys = le.classes_\n",
    "values = le.transform(le.classes_)\n",
    "dictionary = dict(zip(keys, values))\n",
    "\n",
    "print(f'We used Label encoding to work with numerical values instead of categorical.\\n'\\\n",
    "      f'The labels now are: {dictionary}.\\nAlso each column has been normalized ans scaled.')\n",
    "\n",
    "#Splitting dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(decomposed.iloc[:,:-1],\n",
    "                                                    decomposed.Label, test_size=0.2, \n",
    "                                                    random_state=np.random.RandomState(5))\n",
    "\n",
    "#Creating model and predicting output values on testing data.\n",
    "DT = DecisionTreeClassifier(criterion='entropy', random_state=np.random.RandomState(5))\n",
    "DT = DT.fit(X_train,y_train)\n",
    "y_pred = DT.predict(X_test)\n",
    "\n",
    "\n",
    "#Confusion matrix\n",
    "plt.figure(figsize=(8,5))\n",
    "confusion_matrix = pd.crosstab(y_test, y_pred, rownames=['Actual'], \n",
    "                               colnames=['Predicted'])\n",
    "sns.heatmap(confusion_matrix, annot=True)\n",
    "plt.savefig(\"Confusion_Matrix_DT.png\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Accuracy:{metrics.accuracy_score(y_test, y_pred)}\\n\\n\")\n",
    "print(f'More metrics about the model.\\n\\n' \\\n",
    "      f'{metrics.classification_report(y_test, y_pred, labels=[0.0, 1.0, 2.0, 3.0, 4.0])}\\n')\n",
    "roc_dt = metrics.roc_auc_score(y_test, DT.predict_proba(X_test), average = 'weighted', multi_class='ovr')\n",
    "print(f'Area Under Curve score: {roc_dt}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b068bdf6",
   "metadata": {},
   "source": [
    "# Decision Tree layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02302f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from six import StringIO\n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "from graphviz import Source\n",
    "\n",
    "dt = StringIO()\n",
    "export_graphviz(DT, out_file=dt, feature_names = decomposed.columns[:-1], \n",
    "                class_names=decomposed.Label.unique().astype(str))\n",
    "graph = pydotplus.graph_from_dot_data(dt.getvalue()) \n",
    "graph.write_png(\"Decision_Tree_layout.png\")\n",
    "Image(graph.create_png())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bbf8ae",
   "metadata": {},
   "source": [
    "# KNN implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3867e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNN = KNeighborsClassifier(n_neighbors=9)\n",
    "KNN.fit(X_train, y_train)\n",
    "y_pred = KNN.predict(X_test)\n",
    "\n",
    "#Confusion matrix\n",
    "plt.figure(figsize=(8,5))\n",
    "confusion_matrix = pd.crosstab(y_test, y_pred, rownames=['Actual'], \n",
    "                               colnames=['Predicted'])\n",
    "sns.heatmap(confusion_matrix, annot=True)\n",
    "plt.savefig(\"Confusion_Matrix_KNN.png\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Accuracy:{metrics.accuracy_score(y_test, y_pred)}\\n\\n\")\n",
    "\n",
    "print(f'More metrics about the model.\\n\\n' \\\n",
    "      f'{metrics.classification_report(y_test, y_pred, labels=[0.0, 1.0, 2.0, 3.0, 4.0])}')\n",
    "roc_knn = metrics.roc_auc_score(y_test, KNN.predict_proba(X_test), average = 'weighted', multi_class='ovr')\n",
    "print(f'Area Under Curve score: {roc_knn}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08bf46a",
   "metadata": {},
   "source": [
    "# K-Fold function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f307623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold(folds):\n",
    "    split_data = KFold(n_splits = folds, shuffle = True, random_state = np.random.RandomState(5))\n",
    "    return split_data, folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5f3310",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_k, dt_folds = k_fold(3)\n",
    "dt_k_, dt_folds_ = k_fold(5)\n",
    "input_data = decomposed.iloc[:,:-1]\n",
    "label_data = decomposed.Label\n",
    "result = cross_val_score(DT , input_data, label_data, cv = dt_k)\n",
    "print(f\"Average accuracy from 3 folds: {result.mean()}\\n\")\n",
    "result_ = cross_val_score(DT , input_data, label_data, cv = dt_k_)\n",
    "print(f\"Average accuracy from 5 folds: {result_.mean()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9541ed62",
   "metadata": {},
   "source": [
    "# Grid search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a980fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(model, hyper_params, score, folds):\n",
    "    gs = GridSearchCV(estimator = model,\n",
    "    param_grid = hyper_params,\n",
    "    scoring = score,\n",
    "    cv = folds,\n",
    "    return_train_score = True)\n",
    "    return gs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3835be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search for optimal Decision Tree parameters\n",
    "dt_hp = [{'criterion': ['entropy'],\n",
    "       'splitter': ['best', 'random'],\n",
    "       'max_depth': [3,4,5,6,7,None]}]\n",
    "\n",
    "model_gs_ = grid_search(DT, dt_hp, 'accuracy', dt_k_)\n",
    "model_gs_.fit(input_data, label_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f0d971",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model best parameter with {dt_folds_} folds are: {model_gs_.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af70c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rest parameters are default in class object.\n",
    "DT_best_ = DecisionTreeClassifier(criterion='entropy')\n",
    "DT_best_ = DT_best_.fit(X_train,y_train)\n",
    "y_pred_ = DT_best_.predict(X_test)\n",
    "print(f'Decision tree accuracy score with {dt_folds_} and optimal parameters: {metrics.accuracy_score(y_test, y_pred_)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ac3158",
   "metadata": {},
   "source": [
    "# Model Implementation: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4758204",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(random_state=np.random.RandomState(5))\n",
    "RF.fit(X_train,y_train)\n",
    "y_pred=RF.predict(X_test)\n",
    "plt.figure(figsize=(7, 5))\n",
    "confusion_matrix = pd.crosstab(y_test, y_pred, rownames=['Actual'], \n",
    "                               colnames=['Predicted'])\n",
    "sns.heatmap(confusion_matrix, annot=True)\n",
    "plt.savefig(\"Confusion_matrix_RF\")\n",
    "plt.show()\n",
    "print(f\"Accuracy:{metrics.accuracy_score(y_test, y_pred)}\\n\\n\")\n",
    "print(f'More metrics about the model.\\n\\n' \\\n",
    "      f'{metrics.classification_report(y_test, y_pred, labels=[0.0, 1.0, 2.0, 3.0, 4.0])}')\n",
    "roc = metrics.roc_auc_score(y_test, DT.predict_proba(X_test), average = 'weighted', multi_class='ovr')\n",
    "print(f'Area Under Curve score: {roc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6702ce46",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_k, rf_folds = k_fold(3)\n",
    "rf_k_, rf_folds_ = k_fold(5)\n",
    "result = cross_val_score(RF , input_data, label_data, cv = rf_k)\n",
    "print(f\"Average accuracy from 3 folds: {result.mean()}\\n\")\n",
    "result_ = cross_val_score(RF , input_data, label_data, cv = rf_k_)\n",
    "print(f\"Average accuracy from 5 folds: {result_.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeb4b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_hp = [{'n_estimators': [100, 200, 300, 400, 500],\n",
    "          'criterion': ['entropy'],\n",
    "          'max_depth': [5,6,7,None],\n",
    "          'min_samples_split' :[2,4,6],\n",
    "          'min_samples_leaf': [1,2,3],\n",
    "          'random_state': [np.random.RandomState(5)]}]\n",
    "\n",
    "model_gs_ = grid_search(RF, rf_hp, 'accuracy', rf_k_)\n",
    "model_gs_.fit(input_data, label_data)\n",
    "print(f\"Model best parameter with {rf_folds_} folds are: {model_gs_.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d9ca06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rest parameters are default in the class object.\n",
    "RF_best_ = RandomForestClassifier(criterion='entropy',\n",
    "                                  n_estimators = 400,\n",
    "                                  max_depth = None, \n",
    "                                  min_samples_split=4,\n",
    "                                  random_state=np.random.RandomState(5))\n",
    "RF_best_ = RF_best_.fit(X_train,y_train)\n",
    "y_pred_ = RF_best_.predict(X_test)\n",
    "print(f'Decision tree accuracy score with {dt_folds_} and optimal parameters: {metrics.accuracy_score(y_test, y_pred_)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
