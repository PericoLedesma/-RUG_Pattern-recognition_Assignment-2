{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84ea3cac",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6baade51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "### From sklearn - Preprocesing \n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Dimension reduction \n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# K-fold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "\n",
    "# From sklearn - Model creation\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "from sklearn import metrics \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a8d2ae",
   "metadata": {},
   "source": [
    "-----\n",
    "# Reading files and merging features with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0bac7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"data.csv\")\n",
    "\n",
    "dataset_labels = pd.read_csv(\"labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c238d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging both datasets and removing first column\n",
    "dataset = pd.merge(dataset, dataset_labels, on='Unnamed: 0').drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c7f917",
   "metadata": {},
   "source": [
    "----\n",
    "# Analizing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177a57ba",
   "metadata": {},
   "source": [
    "###  Encode the labels of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08ac19fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the labels and updaate values\n",
    "le = preprocessing.LabelEncoder()\n",
    "dataset[\"Class\"] = le.fit_transform(dataset_labels.drop(\"Unnamed: 0\", axis=1).values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa5f0414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let´s store all the labels\n",
    "keys = le.classes_\n",
    "\n",
    "# And now store labels with their encoded value \n",
    "values = le.transform(le.classes_)\n",
    "dictionary = dict(zip(keys, values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f6f281",
   "metadata": {},
   "source": [
    "### Normalize the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b38a0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets store the dataset values without the columns titles\n",
    "x = dataset.iloc[:, :-1].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02904444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let´s create an instance with the normalice function\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "# Let´s fit the normilice function\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "# Let´s put in the dataframe the values scaled\n",
    "dataset.iloc[:, :-1] = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c9e76f",
   "metadata": {},
   "source": [
    "### Output of preprocesing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d47848a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(801, 20532)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e2761e",
   "metadata": {},
   "source": [
    "--------------\n",
    "# Model Implementation:  Esemble methods "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876478f3",
   "metadata": {},
   "source": [
    "###  80% Training data, 20% test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f13ed16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected value dimension reduction \n",
    "lda = LinearDiscriminantAnalysis(n_components=4)\n",
    "\n",
    "# Apply PCA in input vector\n",
    "lda.fit(dataset.iloc[:,:-1],dataset.iloc[:,-1]) \n",
    "\n",
    "# Save results in an np.array\n",
    "reduced = lda.transform(dataset.iloc[:,:-1])\n",
    "\n",
    "# Save labels in an np.array\n",
    "x = dataset['Class'].to_numpy()\n",
    "\n",
    "# Create final dataframe with reduced dimensions\n",
    "dataset_reduced_LDA = pd.DataFrame(np.column_stack((reduced, x)))\n",
    "\n",
    "#For origianl data as input\n",
    "input_data = dataset.iloc[:,:-1].values\n",
    "label_data = dataset.iloc[:,-1].values\n",
    "\n",
    "#For PCA REDUCED data as input\n",
    "#input_data = dataset_reduced_LDA.iloc[:,:-1].values\n",
    "#label_data = dataset_reduced_LDA.iloc[:,-1].values\n",
    "\n",
    "# We split the data  \n",
    "X_train, X_test, y_train, y_test = train_test_split(input_data,label_data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3be8c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=500)\n",
    "dt = DecisionTreeClassifier(criterion='entropy', random_state=np.random.RandomState(5))\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=np.random.RandomState(5))\n",
    "\n",
    "labels = ['Logistic Regression', 'Decision Tree', 'Random Forest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c560f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('Logistic Regression',\n",
       "                              LogisticRegression(max_iter=500)),\n",
       "                             ('Decision Tree',\n",
       "                              DecisionTreeClassifier(criterion='entropy',\n",
       "                                                     random_state=RandomState(MT19937) at 0x7FADA9F00D40)),\n",
       "                             ('Random Forest',\n",
       "                              RandomForestClassifier(random_state=RandomState(MT19937) at 0x7FADA9F00E40))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evc = VotingClassifier(estimators = [(labels[0],lr),(labels[1], dt), (labels[2], rf)], voting = 'hard')\n",
    "\n",
    "evc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98b8c95d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9937888198757764"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a4dfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(evc,input_data,label_data, cv=5).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
